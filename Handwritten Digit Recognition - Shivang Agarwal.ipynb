{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivang/anaconda2/envs/tfdeeplearning/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a dataset of handwritten digits from 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAD8CAYAAAABraMFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYvEjIi+x+BGRl/4fKN5vWqTKBe8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f434e8d0550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as gray scale\n",
    "plt.subplot(221)\n",
    "plt.imshow(mnist.train.images[0].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(mnist.train.images[1].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(mnist.train.images[2].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(mnist.train.images[3].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to help intialize random weights for fully connected or convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as init_weights, but for the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the conv2d function, we'll return an actual convolutional layer here that uses an ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a normal fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.1368\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.8652\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.9095\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.9287\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.938\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.9471\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.9502\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.9554\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.9576\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.9606\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.9633\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.9657\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.9657\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.9678\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.969\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.9713\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.9716\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.9701\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.9725\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.9737\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.9742\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.9756\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.9771\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "0.975\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.977\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.9773\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.9799\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.9796\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.9785\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.9808\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is:\n",
      "0.9815\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is:\n",
      "0.981\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is:\n",
      "0.9812\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is:\n",
      "0.9812\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is:\n",
      "0.9823\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is:\n",
      "0.9833\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is:\n",
      "0.9834\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is:\n",
      "0.9826\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is:\n",
      "0.984\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is:\n",
      "0.984\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "Accuracy is:\n",
      "0.9844\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "Accuracy is:\n",
      "0.9845\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "Accuracy is:\n",
      "0.9824\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "Accuracy is:\n",
      "0.9839\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "Accuracy is:\n",
      "0.9848\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "Accuracy is:\n",
      "0.9848\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "Accuracy is:\n",
      "0.9858\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "Accuracy is:\n",
      "0.9856\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "Accuracy is:\n",
      "0.9855\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "Accuracy is:\n",
      "0.984\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 5000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x , batch_y = mnist.train.next_batch(50)\n",
    "        \n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of 98.4 % in classifying digits."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
